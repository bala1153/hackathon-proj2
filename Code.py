# -*- coding: utf-8 -*-
"""Copy of Welcome To Colaboratory

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t-mcd9SrE9QrOABGjij-LZ0WE037G0oS
"""

# import 'Pandas' 
import pandas as pd 

# import 'Numpy' 
import numpy as np

# import subpackage of Matplotlib
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap

# import 'Seaborn' 
import seaborn as sns

# to suppress warnings 
from warnings import filterwarnings
filterwarnings('ignore')

# display all columns of the dataframe
pd.options.display.max_columns = None

# display all rows of the dataframe
pd.options.display.max_rows = None
 
# to display the float values upto 6 decimal places     
pd.options.display.float_format = '{:.6f}'.format

# import train-test split 
from sklearn.model_selection import train_test_split

# import various functions from statsmodels
import statsmodels
import statsmodels.api as sm

# import StandardScaler to perform scaling
from sklearn.preprocessing import StandardScaler 

# import various functions from sklearn 
from sklearn import metrics
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_curve
from sklearn.metrics import accuracy_score

# import function to perform feature selection
from sklearn.feature_selection import RFE
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2, mutual_info_classif
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import loguniform
from sklearn.ensemble import RandomForestClassifier

df_train = pd.read_csv('training_data.csv')
print(df_train.shape)
# display first five observations using head()
df_train.head()

df_test = pd.read_csv('testing_data.csv')
print(df_test.shape)
# display first five observations using head()
df_test.head()

df = pd.concat([df_train,df_test])
df.head()

df['Guaranteed_Approved _Loan'] = df['Guaranteed_Approved _Loan'].str.replace('Rs.', '').astype(float)
df['ChargedOff_Amount '] = df['ChargedOff_Amount '].str.replace('Rs.', '').astype(float)
df['Gross_Amount_Balance'] = df['Gross_Amount_Balance'].str.replace('Rs.', '').astype(float)
df['Loan_Approved_Gross'] = df['Loan_Approved_Gross'].str.replace('Rs.', '').astype(float)
df['Gross_Amount_Disbursed  '] = df['Gross_Amount_Disbursed  '].str.replace('Rs.', '').astype(float)

df['Revolving_Credit_Line'] = df['Revolving_Credit_Line'].replace(['0','T','R','`','C','1','2','4','.'],['No','Yes','Yes','No','Yes','Yes','Yes','Yes','Yes'])
df['Revolving_Credit_Line'].value_counts()

df['Low_Documentation_Loan'].value_counts()

df['Low_Documentation_Loan'] = df['Low_Documentation_Loan'].replace(['0','S','C','A','R'],['No','Yes','Yes','Yes','Yes'])
df['Low_Documentation_Loan'].value_counts()

#df_train['Jobs_Reatained'] = df_train['Jobs_Reatained'].astype('object')
#df_train['Jobs_Created '] = df_train['Jobs_Created '].astype('object')
#df_train['Count_Employees'] = df_train['Count_Employees'].astype('object')
df['Loan_Term'] = df['Loan_Term'].astype('object')
df['Code_Franchise'] = df['Code_Franchise'].astype('object')

Total = df.isnull().sum().sort_values(ascending=False)          

Percent = (df.isnull().sum()*100/df.isnull().count()).sort_values(ascending=False)   

missing_data = pd.concat([Total, Percent], axis = 1, keys = ['Total', 'Percentage of Missing Values'])    
missing_data

df['Revolving_Credit_Line'] = df['Revolving_Credit_Line'].fillna(df['Revolving_Credit_Line'].mode()[0])
df['Low_Documentation_Loan'] = df['Low_Documentation_Loan'].fillna(df['Low_Documentation_Loan'].mode()[0])
df['Date_Of_Disbursement'] = df['Date_Of_Disbursement'].fillna(df['Date_Of_Disbursement'].mode()[0])
df['Business'] = df['Business'].fillna(df['Business'].mode()[0])
df['Borrower_Name '] = df['Borrower_Name '].fillna(df['Borrower_Name '].mode()[0])

df_target = df['Default']
df_feature = df.drop('Default', axis = 1)

df_feature.columns

df_feature = df_feature.drop('ID', axis = 1)
df_feature = df_feature.drop('Date_Of_Disbursement', axis = 1)
df_feature = df_feature.drop('Classification_Code ', axis = 1)
df_feature = df_feature.drop('Commitment_Date', axis = 1)
df_feature = df_feature.drop('Primary_Loan_Digit', axis = 1)
df_feature = df_feature.drop('Borrower_Name ', axis = 1)

# filter the numerical features in the dataset
# 'select_dtypes' is used to select the variables with given data type
# 'include = [np.number]' will include all the numerical variables
df_num = df_feature.select_dtypes(include = [np.number])

# display numerical features
df_num.columns

# filter the categorical features in the dataset
# 'select_dtypes' is used to select the variables with given data type
# 'include = [np.object]' will include all the categorical variables
df_cat = df_feature.select_dtypes(include = [np.object])

# display categorical features
df_cat.columns

# use 'get_dummies' from pandas to create dummy variables
# use 'drop_first' to create (n-1) dummy variables
dummy_var = pd.get_dummies(data = df_cat, drop_first = True)
dummy_var.head()

# initialize the standard scalar
X_scaler = StandardScaler()

# scale all the numeric variables
# standardize all the columns of the dataframe 'df_num'
num_scaled = X_scaler.fit_transform(df_num)

# create a dataframe of scaled numerical variables
# pass the required column names to the parameter 'columns'
df_num_scaled = pd.DataFrame(num_scaled, columns = df_num.columns)

# standardize the target variable explicitly and store it in a new variable 'y'
#y = (df_target - df_target.mean()) / df_target.std()
y=df_target

df_num_scaled = df_num_scaled.reset_index(drop=True)
dummy_var = dummy_var.reset_index(drop=True)

# concat the dummy variables with numeric features to create a dataframe of all independent variables
# 'axis=1' concats the dataframes along columns 
X = pd.concat([df_num_scaled, dummy_var], axis = 1)

# display first five observations
X.head()

X = sm.add_constant(X)
X_train = X[:105000]
X_test  = X[105000:]

print(X_train.shape)
print(X_test.shape)

y_train = df_target[:105000]

model = LinearRegression()
model.fit(X_train,y_train)
r_sq = model.score(X_train, y_train)
print(f"coefficient of determination: {r_sq}")

def prepare_output_file(y_pred,file_name):
    y_pred_df = pd.DataFrame(y_pred,columns = ["Default"])
    df_test_id = pd.DataFrame(df_test['ID'])
    out = pd.concat([df_test_id,y_pred_df],axis = 1)
    print(out.shape)
    out.to_csv(file_name+".csv")

model_log = LogisticRegression()
model_log.fit(X_train,y_train)
r_sq = model_log.score(X_train, y_train)
print(f"coefficient of determination: {r_sq}")
y_pred=model_log.predict(X_test)
prepare_output_file(y_pred,'logreg')

from sklearn.ensemble import AdaBoostClassifier
ada_model = AdaBoostClassifier(n_estimators = 80, random_state = 10)

# fit the model using fit() on train data
ada_model.fit(X_train, y_train)
r_sq = ada_model.score(X_train, y_train)
print(f"coefficient of determination: {r_sq}")

y_pred=ada_model.predict(X_test)
prepare_output_file(y_pred,'AdaBoost')

"""# New Section"""